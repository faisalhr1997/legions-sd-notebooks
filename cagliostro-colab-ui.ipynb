{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/sd-notebook-collection/blob/main/cagliostro-colab-ui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A6c7-qjDdb0X"
      },
      "outputs": [],
      "source": [
        "#@title ## **Install Stable Diffusion Web UI**\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from subprocess import getoutput\n",
        "from IPython.display import clear_output, display, HTML\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "%store -r \n",
        "\n",
        "# directory\n",
        "root_dir = \"/content\"\n",
        "repo_dir = \"/content/stable-diffusion-webui\"\n",
        "tmp_dir = f\"{root_dir}/tmp\"\n",
        "patches_dir = f\"{root_dir}/patches\"\n",
        "deps_dir = f\"{root_dir}/deps/\"\n",
        "outputs_dir = f\"{repo_dir}/outputs\"\n",
        "components_dir = f\"{repo_dir}/models/components\"\n",
        "models_dir = f\"{repo_dir}/models/Stable-diffusion/\"\n",
        "vaes_dir = f\"{repo_dir}/models/VAE/\"\n",
        "esrgan_dir = f\"{repo_dir}/models/ESRGAN/\"\n",
        "hypernetworks_dir = f\"{repo_dir}/models/hypernetworks/\"\n",
        "embeddings_dir = f\"{repo_dir}/embeddings/\"\n",
        "extensions_dir = f\"{repo_dir}/extensions/\"\n",
        "lora_dir = f\"{repo_dir}/extensions/sd-webui-additional-networks/models/lora\"\n",
        "control_dir = f\"{repo_dir}/extensions/sd-webui-controlnet/models\"\n",
        "annotator_dir = f\"{extensions_dir}/sd-webui-controlnet/annotator/\"\n",
        "with capture.capture_output() as cap:\n",
        "  for dir in [\"root_dir\", \"repo_dir\", \"tmp_dir\", \"outputs_dir\", \"components_dir\", \"models_dir\", \"vaes_dir\", \"esrgan_dir\", \"hypernetworks_dir\", \"embeddings_dir\", \"extensions_dir\", \"lora_dir\", \"control_dir\", \"annotator_dir\"]:\n",
        "    %store {dir}\n",
        "  del cap\n",
        "\n",
        "os.makedirs(patches_dir, exist_ok=True)\n",
        "os.makedirs(deps_dir, exist_ok=True)\n",
        "\n",
        "# url or path\n",
        "A100 = \"https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15+e163309.d20230103.ColabProA100-cp38-cp38-linux_x86_64.whl\"\n",
        "\n",
        "#@markdown ### Experimental\n",
        "try_new_ui_ux = False #@param {type:'boolean'}\n",
        "\n",
        "#@markdown ### Repo Config\n",
        "git_pull = False #@param {type:'boolean'}\n",
        "clean_install = False #@param {type:'boolean'}\n",
        "load_v2_in_vram = True #@param {type:'boolean'}\n",
        "merge_in_vram = True #@param {type:'boolean'}\n",
        "colab_optimizations = True #@param {type:'boolean'}\n",
        "pre_download_annotator = True #@param {type:'boolean'}\n",
        "\n",
        "#@markdown ### Built-In Extensions Config\n",
        "update_extensions = True #@param {type:'boolean'}\n",
        "\n",
        "# model\n",
        "os.chdir(root_dir)\n",
        "\n",
        "remove_dist = [\"/usr/local/lib/python3.8/dist-packages/scipy\",\n",
        "               \"/usr/local/lib/python3.8/dist-packages/scipy-1.7.3.dist-info\",\n",
        "               \"/usr/local/lib/python3.8/dist-packages/scipy.libs\"]\n",
        "\n",
        "package_url = [\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/webui.tar.lz4\",\n",
        "               \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/webui-deps.tar.lz4\",\n",
        "               \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/webui-cache.tar.lz4\"]\n",
        "\n",
        "annotator_url= [\"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-annotator/table5_pidinet.pth\",\n",
        "                \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-annotator/upernet_global_small.pth\",\n",
        "                \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-annotator/res101.pth\",\n",
        "                \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-annotator/dpt_hybrid-midas-501f0c75.pt\",\n",
        "                \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-annotator/mlsd_large_512_fp32.pth\",\n",
        "                \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-annotator/network-bsds500.pth\",\n",
        "                \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-annotator/hand_pose_model.pth\",\n",
        "                \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-annotator/body_pose_model.pth\"]\n",
        "\n",
        "def ubuntu_deps(url, name, dst):\n",
        "  with capture.capture_output() as cap:\n",
        "    !wget -q --show-progress {url}\n",
        "    with zipfile.ZipFile(name, 'r') as deps:\n",
        "      deps.extractall(dst)\n",
        "    !dpkg -i {dst}/*\n",
        "    os.remove(name)\n",
        "    shutil.rmtree(dst)\n",
        "    del cap \n",
        "    \n",
        "def pre_download():\n",
        "  for dist in remove_dist:\n",
        "    if os.path.exists(dist):\n",
        "      shutil.rmtree(dist)\n",
        "\n",
        "  for package in tqdm(package_url, desc='\u001b[1;32mUnpacking WebUI'):\n",
        "    with capture.capture_output() as cap:\n",
        "      package_name = os.path.basename(package)\n",
        "      !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {root_dir} -o {package_name} {package}\n",
        "      if package_name == \"webui-deps.tar.lz4\":\n",
        "        !tar -xI lz4 -f {package_name} --overwrite-dir --directory=/usr/local/lib/python3.8/dist-packages/\n",
        "      else:\n",
        "        !tar -xI lz4 -f {package_name} --directory=/\n",
        "      os.remove(os.path.basename(package_name))\n",
        "      del cap\n",
        "      \n",
        "  if os.path.exists(\"/usr/local/lib/python3.8/dist-packages/ffmpy-0.3.0.dist-info\"):\n",
        "    shutil.rmtree(\"/usr/local/lib/python3.8/dist-packages/ffmpy-0.3.0.dist-info\")\n",
        "\n",
        "  s = getoutput('nvidia-smi')\n",
        "  if not 'T4' in s:\n",
        "    !pip uninstall -y xformers\n",
        "    if 'A100' in s:\n",
        "      %pip -q install {A100}\n",
        "\n",
        "start_install = int(time.time())\n",
        "print(\"\u001b[1;32mInstalling...\\n\", end= \"\")\n",
        "ubuntu_deps(\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/deb-libs.zip\", \"deb-libs.zip\", deps_dir)\n",
        "if clean_install:\n",
        "  if os.path.exists(repo_dir):\n",
        "    print(\"\u001b[1;32mUninstall current Web UI...\")\n",
        "    shutil.rmtree(repo_dir)\n",
        "    pre_download()\n",
        "else:\n",
        "  if not os.path.exists(repo_dir):\n",
        "    pre_download()\n",
        "\n",
        "if try_new_ui_ux:\n",
        "  print(\"\u001b[1;32mUsing new UI/UX from @Anapnoe...\")\n",
        "  with capture.capture_output() as cap:\n",
        "    os.chdir(repo_dir)\n",
        "    if os.path.exists(os.path.join(extensions_dir,\"sd-web-ui-quickcss/style.css\")):\n",
        "      os.remove(os.path.join(extensions_dir,\"sd-web-ui-quickcss/style.css\"))\n",
        "    !git remote set-url origin https://github.com/anapnoe/stable-diffusion-webui/\n",
        "    !git pull\n",
        "    del cap\n",
        "  # temporary fix\n",
        "  more2fill = \"/content/stable-diffusion-webui/html/svg/more-2-fill.svg\"\n",
        "  \n",
        "  if not os.path.exists(more2fill):\n",
        "    shutil.copy(os.path.join(os.path.dirname(more2fill),\"cpu-fill.svg\"), more2fill)\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  if git_pull:\n",
        "    os.chdir(repo_dir)\n",
        "    !git pull -X theirs --rebase --autostash\n",
        "\n",
        "  !wget https://raw.githubusercontent.com/ddPn08/automatic1111-colab/main/patches/stablediffusion-lowram.patch -P {patches_dir}  -c\n",
        "  if load_v2_in_vram:\n",
        "    os.chdir(f\"{repo_dir}/repositories/stable-diffusion-stability-ai\")\n",
        "    !git apply {patches_dir}/stablediffusion-lowram.patch\n",
        "\n",
        "  if colab_optimizations:\n",
        "    !sed -i \"s@os.path.splitext(checkpoint_.*@os.path.splitext(checkpoint_file); map_location='cuda'@\" /content/stable-diffusion-webui/modules/sd_models.py\n",
        "    !sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' /content/stable-diffusion-webui/webui.py\n",
        "\n",
        "  if merge_in_vram:\n",
        "    !sed -i \"s@'cpu'@'cuda'@\" /content/stable-diffusion-webui/modules/extras.py\n",
        "  del cap\n",
        "\n",
        "if pre_download_annotator:\n",
        "  for download in tqdm(annotator_url, desc='\u001b[1;32mPreparing ControlNet Annotator'):\n",
        "    basename = os.path.basename(download)\n",
        "    with capture.capture_output() as cap:\n",
        "      !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {tmp_dir} -o {basename} {download}\n",
        "      del cap\n",
        "      \n",
        "  for path in [\"pidinet/table5_pidinet.pth\", \n",
        "              \"uniformer/upernet_global_small.pth\", \n",
        "              \"leres/res101.pth\", \n",
        "              \"midas/dpt_hybrid-midas-501f0c75.pt\", \n",
        "              \"mlsd/mlsd_large_512_fp32.pth\", \n",
        "              \"hed/network-bsds500.pth\",  \n",
        "              \"openpose/hand_pose_model.pth\",  \n",
        "              \"openpose/body_pose_model.pth\"]:\n",
        "\n",
        "    annotator_name = os.path.basename(path)\n",
        "    annotator_path = os.path.join(annotator_dir, path)\n",
        "    annotator_src = os.path.join(tmp_dir, annotator_name)\n",
        "    annotator_dst = os.path.dirname(annotator_path)\n",
        "\n",
        "    if os.path.exists(annotator_path):\n",
        "      os.remove(annotator_path)\n",
        "    if not path.endswith(\"upernet_global_small.pth\"):\n",
        "      shutil.move(annotator_src, annotator_dst)\n",
        "    else:\n",
        "      segmentation_path = \"/root/.cache/torch/hub/checkpoints\"\n",
        "      os.makedirs(segmentation_path, exist_ok=True)\n",
        "      if os.path.exists(os.path.join(segmentation_path, annotator_name)):\n",
        "        os.remove(os.path.join(segmentation_path, annotator_name))\n",
        "      shutil.copy(annotator_src, os.path.join(segmentation_path, annotator_name))\n",
        "      shutil.move(annotator_src, annotator_dst)\n",
        "\n",
        "install_time = timedelta(seconds=time.time()-start_install)\n",
        "print(\"\u001b[1;32mFinished unpacking. Took\",\"%02d:%02d:%02d \\n\" % (install_time.seconds / 3600, (install_time.seconds / 60) % 60, install_time.seconds % 60), end='', flush=True)\n",
        "\n",
        "if update_extensions:\n",
        "  update = int(time.time())\n",
        "  extensions_updated = []\n",
        "  with tqdm(total=len(os.listdir(extensions_dir)), desc=\"\u001b[1;32mUpdating extensions\",  mininterval=0) as pbar:\n",
        "    for dir in os.listdir(extensions_dir):\n",
        "      if os.path.isdir(os.path.join(extensions_dir, dir)):\n",
        "        os.chdir(os.path.join(extensions_dir, dir))\n",
        "        with capture.capture_output() as cap:\n",
        "          !git fetch origin\n",
        "          !git pull\n",
        "          \n",
        "        output = cap.stdout.strip()\n",
        "        if \"Already up to date.\" not in output:\n",
        "          extensions_updated.append(dir)\n",
        "        pbar.update(1)\n",
        "  print(\"\\n\")\n",
        "  for ext in extensions_updated:\n",
        "    print(f\"\u001b[1;32m{ext} updated to new version\")\n",
        "\n",
        "  update_time = timedelta(seconds=time.time()-update)\n",
        "  print(\"\\n\u001b[1;32mAll extensions are up to date. Took\",\"%02d:%02d:%02d\" % (update_time.seconds / 3600, (update_time.seconds / 60) % 60, update_time.seconds % 60), end='', flush=True)\n",
        "\n",
        "print('\\n\u001b[1;32mAll is done! Go to the next step.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qgvihy5BQ3II"
      },
      "outputs": [],
      "source": [
        "#@title ## **Download Model and VAE**\n",
        "import os\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "#@markdown ### Available Model\n",
        "anything_v3_2 = False #@param {type: 'boolean'}\n",
        "anything_v3_3 = False #@param {type: 'boolean'}\n",
        "hitokomoru_v1_5 = False #@param {type: 'boolean'}\n",
        "pastelmix = False #@param {type: 'boolean'}\n",
        "waifu_diffusion_v1_4_e2 = False #@param {type: 'boolean'}\n",
        "replicant_v1 = True #@param {type: 'boolean'}\n",
        "chillout_mix = False #@param {type: 'boolean'}\n",
        "illuminati_diffusion = False #@param {type: 'boolean'}\n",
        "stable_diffusion_v1_5 = False #@param {type: 'boolean'}\n",
        "#@markdown ### Available VAE\n",
        "anime = True #@param {type: 'boolean'}\n",
        "waifu_diffusion = False #@param {type: 'boolean'}\n",
        "stable_diffusion = False #@param {type: 'boolean'}\n",
        "#@markdown ### Available ControlNet Model\n",
        "#@markdown All ControlNet model below is based on SDv1 model, so it doesn't work if your model is based on `SDv2 Base` and `SDv2 768v`. <br>\n",
        "#@markdown `e.g.: Waifu DIffusion V1.4-V1.5, Illuminati Diffusion, and Replicant V1.0`\n",
        "\n",
        "control_model = False #@param {type: 'boolean'}\n",
        "diff_control_model = True #@param {type: 'boolean'}\n",
        "t2i_adapter_model = False #@param {type: 'boolean'}\n",
        "\n",
        "installModels = []\n",
        "installVAE = []\n",
        "\n",
        "modelList = [\"anything_v3_2\",\n",
        "             \"anything_v3_3\",\n",
        "             \"hitokomoru_v1_5\",\n",
        "             \"pastelmix\",\n",
        "             \"waifu_diffusion_v1_4_e2\",\n",
        "             \"replicant_v1\",\n",
        "             \"chillout_mix\",\n",
        "             \"illuminati_diffusion\",\n",
        "             \"stable_diffusion_v1_5\"]\n",
        "modelUrl = [\"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-2.safetensors\",\n",
        "            \"https://huggingface.co/cag/anything-v3-3/resolve/main/anything-v3-3.safetensors\",\n",
        "            \"https://huggingface.co/Linaqruf/hitokomoru-diffusion-v1-5/resolve/main/hitokomoru-v1-5.safetensors\",\n",
        "            \"https://huggingface.co/andite/pastel-mix/resolve/main/pastelmix-fp32.safetensors\", \n",
        "            \"https://huggingface.co/saltacc/wd-1-4-anime/resolve/main/wd-1-4-epoch2-fp16.safetensors\",\n",
        "            \"https://huggingface.co/gsdf/Replicant-V1.0/resolve/main/Replicant-V1.0_fp16.safetensors\",\n",
        "            \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/chillout_mix-pruned.safetensors\", \n",
        "            \"https://huggingface.co/IlluminatiAI/Illuminati_Diffusion_v1.0/resolve/main/illuminati_diffusion_v1.0.safetensors\", \n",
        "            \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors\"]\n",
        "\n",
        "vaeList = [\"anime\",\n",
        "           \"waifu_diffusion\",\n",
        "           \"stable_diffusion\"]\n",
        "\n",
        "vaeUrl = [\"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\",\n",
        "          \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\",\n",
        "          \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\"]\n",
        "  \n",
        "controlUrl = [\"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/control_canny-fp16.safetensors\",           \n",
        "              \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/control_depth-fp16.safetensors\",\n",
        "              \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/control_hed-fp16.safetensors\",\n",
        "              \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/control_mlsd-fp16.safetensors\",\n",
        "              \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/control_normal-fp16.safetensors\",\n",
        "              \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/control_openpose-fp16.safetensors\",\n",
        "              \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/control_scribble-fp16.safetensors\",\n",
        "              \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/control_seg-fp16.safetensors\"]\n",
        "\n",
        "diffControlUrl = [\"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/diff_control_sd15_canny_fp16.safetensors\",           \n",
        "                  \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/diff_control_sd15_depth_fp16.safetensors\",\n",
        "                  \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/diff_control_sd15_hed_fp16.safetensors\",\n",
        "                  \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/diff_control_sd15_mlsd_fp16.safetensors\",\n",
        "                  \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/diff_control_sd15_normal_fp16.safetensors\",\n",
        "                  \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/diff_control_sd15_openpose_fp16.safetensors\",\n",
        "                  \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/diff_control_sd15_scribble_fp16.safetensors\",\n",
        "                  \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/diff_control_sd15_seg_fp16.safetensors\"]\n",
        "\n",
        "t2iAdapterUrl = [\"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/t2iadapter_keypose-fp16.safetensors\",\n",
        "                 \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/t2iadapter_seg-fp16.safetensors\",\n",
        "                 \"https://huggingface.co/Linaqruf/stolen/resolve/main/controlnet-extracted-model/t2iadapter_sketch-fp16.safetensors\"]\n",
        "\n",
        "for i, model in enumerate(modelList):\n",
        "    if locals()[model]: # if checkbox is checked\n",
        "        installModels.append((model, modelUrl[i]))\n",
        "\n",
        "for i, vae in enumerate(vaeList):\n",
        "    if locals()[vae]: # if checkbox is checked\n",
        "        installVAE.append((vae, vaeUrl[i]))\n",
        "        \n",
        "def install(checkpoint_name, url, is_vae=None, is_control=None):\n",
        "  basename = os.path.basename(url)\n",
        "  hf_token = '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' \n",
        "  user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\\\n",
        "\n",
        "  if is_vae:\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {vaes_dir} -o {checkpoint_name}.vae.pt {url}\n",
        "  elif is_control:\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {control_dir} -o {checkpoint_name} {url}\n",
        "  else:\n",
        "    ext = \"ckpt\" if url.endswith(\".ckpt\") else \"safetensors\"\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {models_dir} -o {checkpoint_name}.{ext} {url}\n",
        "\n",
        "print(f\"\u001b[1;32mDownloading...\")\n",
        "downloading = int(time.time())\n",
        "\n",
        "downloaded_model=[]\n",
        "downloaded_vae=[]\n",
        "downloaded_control_model=[]\n",
        "downloaded_diff_control_model=[]\n",
        "downloaded_t2i_adapter_model=[]\n",
        "\n",
        "for model in tqdm(installModels, desc=\"\u001b[1;32mDownloading Models\"):\n",
        "  with capture.capture_output() as cap:\n",
        "    install(model[0], model[1], is_vae=False, is_control=False)\n",
        "    downloaded_model.append(model[0])\n",
        "    del cap\n",
        "\n",
        "for vae in tqdm(installVAE, desc=\"\u001b[1;32mDownloading VAE\"):\n",
        "  with capture.capture_output() as cap:\n",
        "    install(vae[0], vae[1], is_vae=True,  is_control=False)\n",
        "    downloaded_vae.append(vae[0])\n",
        "    del cap\n",
        "\n",
        "if control_model:\n",
        "  for control in tqdm(controlUrl, desc=\"\u001b[1;32mDownloading ControlNet Model\"):\n",
        "    basename = os.path.basename(control)\n",
        "    with capture.capture_output() as cap:\n",
        "      install(basename, control, is_vae=False, is_control=True)\n",
        "      downloaded_control_model.append(basename)\n",
        "      del cap\n",
        "\n",
        "if diff_control_model:\n",
        "  for control in tqdm(diffControlUrl, desc=\"\u001b[1;32mDownloading Difference ControlNet Model\"):\n",
        "    basename = os.path.basename(control)\n",
        "    with capture.capture_output() as cap:\n",
        "      install(basename, control, is_vae=False, is_control=True)\n",
        "      downloaded_diff_control_model.append(basename)\n",
        "      del cap\n",
        "\n",
        "if t2i_adapter_model:\n",
        "  for adapter in tqdm(t2iAdapterUrl, desc=\"\u001b[1;32mDownloading Text2Image Adapter Model\"):\n",
        "    basename = os.path.basename(adapter)\n",
        "    with capture.capture_output() as cap:\n",
        "      install(basename, adapter, is_vae=False, is_control=True)\n",
        "      downloaded_t2i_adapter_model.append(basename)\n",
        "      del cap\n",
        "\n",
        "download_time = timedelta(seconds=time.time()-downloading)\n",
        "\n",
        "print(\"\\n\u001b[1;32mDownload completed. Took\",\"%02d:%02d:%02d \\n\" % (download_time.seconds / 3600, (download_time.seconds / 60) % 60, download_time.seconds % 60), end='', flush=True)\n",
        "print('\\n\u001b[1;32mAll is done! Go to the next step\\n', end=\"\")\n",
        "\n",
        "print(\"\\n\\033[92m\\033[1mDownloaded Models\\033[96m\")\n",
        "for model in downloaded_model:\n",
        "  print(f\"- {model}\") \n",
        "print(\"\\n\\033[92m\\033[1mDownloaded VAEs\\033[96m\")\n",
        "for vae in downloaded_vae:\n",
        "  print(f\"- {vae}\")\n",
        "if control_model:\n",
        "  print(\"\\n\\033[92m\\033[1mDownloaded Control Model:\\033[96m\") \n",
        "  for model in downloaded_control_model:\n",
        "    print(f\"- {model}\")\n",
        "if diff_control_model:\n",
        "  print(\"\\n\\033[92m\\033[1mDownloaded Difference Control Model:\\033[96m\") \n",
        "  for model in downloaded_diff_control_model:\n",
        "    print(f\"- {model}\")\n",
        "if t2i_adapter_model:\n",
        "  print(\"\\n\\033[92m\\033[1mDownloaded Text2Image Adapter Model:\\033[96m\") \n",
        "  for model in downloaded_t2i_adapter_model:\n",
        "    print(f\"- {model}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "euzt0QG35aEO"
      },
      "outputs": [],
      "source": [
        "#@title ## **Custom Download Corner**\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "#@markdown Fill in the URL fields with the links to the files you want to download. Separate multiple URLs with a comma.\n",
        "#@markdown Example: `url1, url2, url3`\n",
        "os.chdir(root_dir)\n",
        "\n",
        "custom_download_list = []\n",
        "\n",
        "custom_model_url = \"\" #@param {'type': 'string'}\n",
        "custom_vae_url = \"\" #@param {'type': 'string'}\n",
        "custom_embedding_url = \"\" #@param {'type': 'string'}\n",
        "custom_LoRA_url = \"\" #@param {'type': 'string'}\n",
        "custom_hypernetwork_url = \"\" #@param {'type': 'string'}\n",
        "custom_control_url = \"\" #@param {'type': 'string'}\n",
        "custom_extensions_url = \"\" #@param {'type': 'string'}\n",
        "custom_components_url = \"\" #@param {'type': 'string'}\n",
        "custom_upscaler_url = \"\" #@param {'type': 'string'}\n",
        "\n",
        "def download(url_list, dst_dir, download_list, is_extensions):\n",
        "  downloaded=[]\n",
        "  for url in tqdm(url_list, desc=\"\u001b[1;32mDownloading Custom URLs\"):\n",
        "    if url:\n",
        "      url = url.strip()\n",
        "      download_list.append(url)\n",
        "      basename = os.path.basename(url)\n",
        "      \n",
        "      with capture.capture_output() as cap:\n",
        "        if is_extensions:\n",
        "            os.chdir(extensions_dir)\n",
        "            !git clone {url}\n",
        "        elif url.startswith(\"https://drive.google.com\"):\n",
        "            os.chdir(models_dir)\n",
        "            !gdown --fuzzy {url}\n",
        "        elif url.startswith(\"https://huggingface.co/\"):\n",
        "            if '/blob/' in url:\n",
        "                url = url.replace('/blob/', '/resolve/')\n",
        "            hf_token = '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'\n",
        "            user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "            !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {dst_dir} -o {basename} {url}\n",
        "        else:\n",
        "            !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {dst_dir} {url}\n",
        "      del cap\n",
        "      downloaded.append((basename, dst_dir))\n",
        "  print(\"\\n\")\n",
        "  print(\"\\033[92m\\033[1mDownloaded URLs\\033[96m\")\n",
        "  for item in downloaded:\n",
        "    print(f\"- {item[0]}\")\n",
        "      \n",
        "custom_download_list = []\n",
        "\n",
        "custom_dirs = {\n",
        "  custom_model_url: models_dir,\n",
        "  custom_vae_url: vaes_dir,\n",
        "  custom_embedding_url: embeddings_dir,\n",
        "  custom_LoRA_url: lora_dir,\n",
        "  custom_hypernetwork_url: hypernetworks_dir,\n",
        "  custom_control_url: control_dir,\n",
        "  custom_extensions_url: extensions_dir,\n",
        "  custom_components_url: components_dir,\n",
        "  custom_upscaler_url: esrgan_dir\n",
        "}\n",
        "\n",
        "print(f\"\u001b[1;32mDownloading...\")\n",
        "downloading = int(time.time())\n",
        "\n",
        "for custom_url in [custom_model_url,\n",
        "                   custom_vae_url,\n",
        "                   custom_embedding_url,\n",
        "                   custom_LoRA_url,\n",
        "                   custom_hypernetwork_url,\n",
        "                   custom_control_url,\n",
        "                   custom_extensions_url,\n",
        "                   custom_components_url,\n",
        "                   custom_upscaler_url]:\n",
        "  if custom_url:\n",
        "    urls = custom_url.split(\",\")\n",
        "    download(urls,\n",
        "             custom_dirs[custom_url],\n",
        "             custom_download_list,\n",
        "             custom_url == custom_extensions_url)\n",
        "\n",
        "download_time = timedelta(seconds=time.time()-downloading)\n",
        "\n",
        "print(\"\\n\u001b[1;32mDownload completed. Took\",\"%02d:%02d:%02d\" % (download_time.seconds / 3600, (download_time.seconds / 60) % 60, download_time.seconds % 60), end='', flush=True)\n",
        "print('\\n\u001b[1;32mAll is done! Go to the next step.', end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SaAJk33ppFw1"
      },
      "outputs": [],
      "source": [
        "#@title ## **Start Stable Diffusion Web UI**\n",
        "import os\n",
        "import random\n",
        "%store -r \n",
        "\n",
        "#@markdown ### Gradio Auth\n",
        "user = \"\" #@param {type:\"string\"}\n",
        "password= \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Alternative Tunnel\n",
        "#@markdown > Get <b>your</b> token for ngrok [here](https://dashboard.ngrok.com/get-started/your-authtoken) \n",
        "ngrok_token = \"\" #@param {type: 'string'}\n",
        "ngrok_region = \"ap\" #@param [\"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "\n",
        "#@markdown ### ControlNet Config:\n",
        "multi_controlnet = 2 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "controlnet_py = \"/content/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\"\n",
        "!sed -i 's/\\(shared\\.opts\\.data\\.get(\"control_net_max_models_num\",\\) [0-9]*/\\1 '\"$multi_controlnet\"'/' {controlnet_py}\n",
        "\n",
        "#@markdown ### Arguments\n",
        "\n",
        "medvram = False #@param {type: 'boolean'}\n",
        "load_in_vram = True #@param {type: 'boolean'}\n",
        "silent_launch = True #@param {type: 'boolean'}\n",
        "auto_vae = True #@param {type: 'boolean'}\n",
        "auto_model = True #@param {type: 'boolean'}\n",
        "fix_black_result = True #@param {type: 'boolean'}\n",
        "additional_args = \"--xformers\" #@param {type: 'string'}\n",
        "\n",
        "if auto_model:\n",
        "  models_list = os.listdir(models_dir)\n",
        "  model_files = [f for f in models_list if f.endswith(('.ckpt','.safetensors'))]\n",
        "  if model_files:\n",
        "      model_path = os.path.join(models_dir, random.choice(model_files))\n",
        "else:\n",
        "  model_path = os.path.join(models_dir, \"anything-v3-3.safetensors\")\n",
        "  \n",
        "if auto_vae:\n",
        "  vaes_list = os.listdir(vaes_dir)\n",
        "  vae_files = [f for f in vaes_list if f.endswith('.vae.pt')]\n",
        "  if vae_files:\n",
        "      vae_path = os.path.join(vaes_dir, random.choice(vae_files))\n",
        "else:\n",
        "  vae_path = os.path.join(vaes_dir, \"anime.vae.pt\")\n",
        "        \n",
        "os.chdir(repo_dir)\n",
        "\n",
        "print(\"\u001b[1;32m\")\n",
        "\n",
        "!python launch.py \\\n",
        "  --enable-insecure-extension-access \\\n",
        "  --disable-safe-unpickle \\\n",
        "  --lora-dir {lora_dir} \\\n",
        "  {\"--ckpt \" + model_path if os.path.exists(model_path) else \"\"} \\\n",
        "  {\"--vae-path \" + vae_path if os.path.exists(vae_path) else \"\"} \\\n",
        "  {\"--medvram\" if medvram else \"\"} \\\n",
        "  {\"--share\" if not ngrok_token else \"\"} \\\n",
        "  {\"--gradio-auth \" + user + \":\" + password if user and password else \"\"} \\\n",
        "  {\"--no-half-vae\" if fix_black_result else \"\"} \\\n",
        "  {\"--lowram\" if load_in_vram else \"\"} \\\n",
        "  {\"--no-hashing\" if silent_launch else \"\"} \\\n",
        "  {\"--disable-console-progressbars\" if silent_launch else \"\"} \\\n",
        "  {\"--ngrok \" + ngrok_token if ngrok_token else \"\"} \\\n",
        "  {\"--ngrok-region \" + ngrok_region if ngrok_token else \"\"} \\\n",
        "  --opt-sub-quad-attention \\\n",
        "  --opt-channelslast \\\n",
        "  --theme dark \\\n",
        "  {additional_args}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ojb4nAieATxI"
      },
      "outputs": [],
      "source": [
        "#@title ## **Download Generated Images**\n",
        "#@markdown Download file manually from files tab or save to Google Drive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import drive\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "%store -r \n",
        "\n",
        "os.chdir(outputs_dir)\n",
        "\n",
        "use_drive = True #@param {type:\"boolean\"}\n",
        "folder_name = \"AI-generated Art\" #@param {type: \"string\"}\n",
        "filename = \"replicant.zip\" #@param {type: \"string\"}\n",
        "save_as = filename \n",
        "\n",
        "if os.path.exists(filename):\n",
        "    i = 1\n",
        "    while os.path.exists(f\"waifu({i}).zip\"):\n",
        "        i += 1\n",
        "    filename = f\"waifu({i}).zip\"\n",
        "\n",
        "!zip -r /content/outputs.zip .\n",
        "\n",
        "if use_drive:   \n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "\n",
        "    def create_folder(folder_name):\n",
        "        file_list = drive.ListFile({'q': \"title='{}' and mimeType='application/vnd.google-apps.folder' and trashed=false\".format(folder_name)}).GetList()\n",
        "        if len(file_list) > 0:\n",
        "            print('Debug: Folder exists')\n",
        "            folder_id = file_list[0]['id']\n",
        "        else:\n",
        "            print('Debug: Creating folder')\n",
        "            file = drive.CreateFile({'title': folder_name, 'mimeType': 'application/vnd.google-apps.folder'})\n",
        "            file.Upload()\n",
        "            folder_id = file.attr['metadata']['id']\n",
        "        return folder_id\n",
        "\n",
        "    def upload_file(file_name, folder_id, save_as):\n",
        "        file_list = drive.ListFile({'q': \"title='{}' and trashed=false\".format(save_as)}).GetList()\n",
        "        if len(file_list) > 0:\n",
        "            print('Debug: File already exists')\n",
        "            i = 1\n",
        "            while True:\n",
        "                new_name = os.path.splitext(save_as)[0] + f\"({i})\" + os.path.splitext(save_as)[1]\n",
        "                file_list = drive.ListFile({'q': \"title='{}' and trashed=false\".format(new_name)}).GetList()\n",
        "                if len(file_list) == 0:\n",
        "                    save_as = new_name\n",
        "                    break\n",
        "                i += 1\n",
        "        file = drive.CreateFile({'title': save_as, 'parents': [{'id': folder_id}]})\n",
        "        file.SetContentFile(file_name)\n",
        "        file.Upload()\n",
        "        file.InsertPermission({'type': 'anyone', 'value': 'anyone', 'role': 'reader'})\n",
        "        return file.attr['metadata']['id']\n",
        "\n",
        "    file_id = upload_file('/content/outputs.zip', create_folder(folder_name), save_as)\n",
        "    print(\"Your sharing link: https://drive.google.com/file/d/\" + file_id + \"/view?usp=sharing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SUHPtGLz2m4"
      },
      "source": [
        "# Extras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EGXqJLXwnJQB"
      },
      "outputs": [],
      "source": [
        "#@title ## **Download Generated Images V2**\n",
        "from IPython.utils import capture\n",
        "from huggingface_hub import login\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "#@markdown Download your output by upload it to **Huggingface** instead of Google Drive.\n",
        "#@markdown > Get **your** huggingface `WRITE` token [here](https://huggingface.co/settings/tokens)\n",
        "write_token = \"\" #@param {type:\"string\"}\n",
        "#@markdown Specify where is your repo located, it will automatically create your repo if you didn't have one.\n",
        "repo_name = \"ai-art-dump\" #@param{type:\"string\"}\n",
        "repo_name = repo_name.replace(\" \", \"-\")\n",
        "private_repo = False #@param{type:\"boolean\"}\n",
        "#@markdown This will be compressed to zip and uploaded to datasets repo\n",
        "project_name = \"waifu\" #@param {type :\"string\"}\n",
        "project_name = project_name.replace(\" \", \"_\")\n",
        "\n",
        "if not project_name:\n",
        "  project_name = \"waifu\"\n",
        "\n",
        "output_dir = \"/content/stable-diffusion-webui/outputs\"\n",
        "dataset_zip = project_name + \".zip\"\n",
        "output_path = os.path.join(root_dir, dataset_zip)\n",
        "commit_message = \"Feat: Upload \"+ dataset_zip +\" with Cagliostro Colab UI\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  login(write_token, add_to_git_credential=True) \n",
        "output = cap.stdout.strip()\n",
        "if \"Token is valid.\" in output:\n",
        "  print(\"\u001b[1;32mLogin Succesful.\")\n",
        "\n",
        "api = HfApi()\n",
        "user = api.whoami(write_token)\n",
        "\n",
        "datasets_repo = user['name']+\"/\"+repo_name.strip()\n",
        "\n",
        "if repo_name:\n",
        "  try:\n",
        "    validate_repo_id(datasets_repo)\n",
        "    api.create_repo(repo_id=datasets_repo,\n",
        "                    repo_type=\"dataset\",\n",
        "                    private=private_repo)\n",
        "    print(f\"\u001b[1;32mRepo created, located at https://huggingface.co/datasets/{datasets_repo}\")\n",
        "\n",
        "  except HfHubHTTPError as e:\n",
        "    print(f\"\u001b[1;32mRepo exist, skipping...\")\n",
        "\n",
        "os.chdir(output_dir)\n",
        "print(f\"\u001b[1;32mCompressing to ZIP...\")\n",
        "with capture.capture_output() as cap:\n",
        "  !zip -rv {output_path} .\n",
        "\n",
        "print(f\"\u001b[1;32mUploading generated images... Please wait...\")\n",
        "\n",
        "api.upload_file(\n",
        "  path_or_fileobj=output_path,\n",
        "  path_in_repo=dataset_zip,\n",
        "  repo_id=datasets_repo,\n",
        "  repo_type=\"dataset\",\n",
        "  commit_message=commit_message,\n",
        "  )\n",
        "\n",
        "print(f\"\u001b[1;32mUpload success, download directly at https://huggingface.co/datasets/{datasets_repo}/resolve/main/{dataset_zip}\")\n",
        "\n",
        "os.remove(output_path)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
